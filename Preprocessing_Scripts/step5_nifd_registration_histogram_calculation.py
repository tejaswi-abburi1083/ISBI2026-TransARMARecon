# -*- coding: utf-8 -*-
"""Step5_nifd_registration_histogram_calculation.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1u8eSLD8DH3Xeor-0q2ZoVYsJ5FiXJRjD
"""

from google.colab import drive
drive.mount('/content/drive')

import nibabel as nib

dwi_file = "/content/drive/MyDrive/TejaswiAbburi_va797/Dataset/NIFD_complete_dataset/NIFD_Controls/NIFD_processed_controls/1_S_0107_M_66_Controls/4d_img_DTI_4d_img_1_S_0107_Controls.nii.gz"

img = nib.load(dwi_file)
data = img.get_fdata()

print("Shape:", data.shape)

import os
import nibabel as nib

base_dir = "/content/drive/MyDrive/TejaswiAbburi_va797/Dataset/NIFD_complete_dataset/NIFD_Controls/NIFD_processed_controls"

subjects = sorted(os.listdir(base_dir))

print("===== Diffusion volumes (4th dim) for each subject =====")
for subj in subjects:
    subj_path = os.path.join(base_dir, subj)
    if not os.path.isdir(subj_path):
        continue

    # find the 4D DWI file (.nii.gz)
    dwi_file = None
    for f in os.listdir(subj_path):
        if f.endswith(".nii.gz") and "4d" in f.lower():  # heuristic match
            dwi_file = os.path.join(subj_path, f)
            break

    if dwi_file is None:
        print(f"⚠️ Skipping {subj} (no 4D DWI file found)")
        continue

    # load and check shape
    img = nib.load(dwi_file)
    shape = img.shape

    if len(shape) != 4:
        print(f"⚠️ {subj} → not 4D (shape={shape})")
        continue

    n_volumes = shape[3]
    print(f"{subj} : {n_volumes} volumes (4th dim)")

import os
import nibabel as nib

base_dir = "/content/drive/MyDrive/TejaswiAbburi_va797/Dataset/NIFD_complete_dataset/NIFD_Patients/NIFD_complete_Patients_final"

subjects = sorted(os.listdir(base_dir))

print("===== Diffusion volumes (4th dim) for each subject =====")
for subj in subjects:
    subj_path = os.path.join(base_dir, subj)
    if not os.path.isdir(subj_path):
        continue

    # find the 4D DWI file (.nii.gz)
    dwi_file = None
    for f in os.listdir(subj_path):
        if f.endswith(".nii.gz") and "4d" in f.lower():  # heuristic match
            dwi_file = os.path.join(subj_path, f)
            break

    if dwi_file is None:
        print(f"⚠️ Skipping {subj} (no 4D DWI file found)")
        continue

    # load and check shape
    img = nib.load(dwi_file)
    shape = img.shape

    if len(shape) != 4:
        print(f" {subj} → not 4D (shape={shape})")
        continue

    n_volumes = shape[3]
    print(f"{subj} : {n_volumes} volumes (4th dim)")

!pip install antspyx

"""## Controls JHU Registration"""

import os
import ants

nifd_base = "/content/drive/MyDrive/TejaswiAbburi_va797/Dataset/NIFD_complete_dataset/NIFD_Controls/NIFD_Controls_DTI_parameters"
moving_image_path = "/content/drive/MyDrive/TejaswiAbburi_va797/Dataset/FMRIB58_FA_1mm.nii.gz"
label_image_path = "/content/drive/MyDrive/TejaswiAbburi_va797/Dataset/JHU-ICBM-labels-1mm.nii.gz"
output_folder = "/content/drive/MyDrive/TejaswiAbburi_va797/Dataset/NIFD_complete_dataset/registered_JHU_labels"

os.makedirs(output_folder, exist_ok=True)

for subject_id in sorted(os.listdir(nifd_base)):
    subject_path = os.path.join(nifd_base, subject_id)
    if not os.path.isdir(subject_path):
        continue


    fa_file = None
    for f in os.listdir(subject_path):
        if f.startswith("tensor_fa") and f.endswith(".nii.gz"):
            fa_file = os.path.join(subject_path, f)
            break

    if fa_file is None:
        print(f"Skipping {subject_id} (FA file not found)")
        continue

    print(f"Processing subject {subject_id} ...")

    fixed = ants.image_read(fa_file)
    moving = ants.image_read(moving_image_path)


    mytx = ants.registration(fixed=fixed, moving=moving, type_of_transform="SyN")

    label_image = ants.image_read(label_image_path)
    transformed_label = ants.apply_transforms(
        fixed=fixed,
        moving=label_image,
        interpolator="nearestNeighbor",
        transformlist=mytx["fwdtransforms"]
    )


    reg_label_path = os.path.join(output_folder, f"{subject_id}_JHU_labels.nii.gz")
    ants.image_write(transformed_label, reg_label_path)

    warp_path = os.path.join(output_folder, f"{subject_id}_warp.nii.gz")
    affine_path = os.path.join(output_folder, f"{subject_id}_affine.mat")

    ants.image_write(ants.image_read(mytx["fwdtransforms"][0]), warp_path)
    with open(mytx["fwdtransforms"][1], "rb") as src, open(affine_path, "wb") as dst:
        dst.write(src.read())

    print(f"Saved registered JHU atlas for {subject_id}")

"""## Patients JHU Registration"""

import os
import ants

# Paths
nifd_base = "/content/drive/MyDrive/TejaswiAbburi_va797/Dataset/NIFD_complete_dataset/NIFD_Patients/NIFD_Patients_DTI_parameters"
moving_image_path = "/content/drive/MyDrive/TejaswiAbburi_va797/Dataset/FMRIB58_FA_1mm.nii.gz"
label_image_path = "/content/drive/MyDrive/TejaswiAbburi_va797/Dataset/JHU-ICBM-labels-1mm.nii.gz"
output_folder = "/content/drive/MyDrive/TejaswiAbburi_va797/Dataset/NIFD_complete_dataset/registered_JHU_labels_Patients"

os.makedirs(output_folder, exist_ok=True)

# Loop over subjects
for subject_id in sorted(os.listdir(nifd_base)):
    subject_path = os.path.join(nifd_base, subject_id)
    if not os.path.isdir(subject_path):
        continue

    # Find FA file inside subject folder
    fa_file = None
    for f in os.listdir(subject_path):
        if f.startswith("tensor_fa") and f.endswith(".nii.gz"):
            fa_file = os.path.join(subject_path, f)
            break

    if fa_file is None:
        print(f"Skipping {subject_id} (FA file not found)")
        continue

    print(f"Processing subject {subject_id} ...")

    # Load fixed (subject FA) and moving (template FA)
    fixed = ants.image_read(fa_file)
    moving = ants.image_read(moving_image_path)

    # Register
    mytx = ants.registration(fixed=fixed, moving=moving, type_of_transform="SyN")

    # Apply warp to JHU atlas
    label_image = ants.image_read(label_image_path)
    transformed_label = ants.apply_transforms(
        fixed=fixed,
        moving=label_image,
        interpolator="nearestNeighbor",
        transformlist=mytx["fwdtransforms"]
    )

    # Save outputs
    reg_label_path = os.path.join(output_folder, f"{subject_id}_JHU_labels.nii.gz")
    ants.image_write(transformed_label, reg_label_path)

    warp_path = os.path.join(output_folder, f"{subject_id}_warp.nii.gz")
    affine_path = os.path.join(output_folder, f"{subject_id}_affine.mat")

    ants.image_write(ants.image_read(mytx["fwdtransforms"][0]), warp_path)
    with open(mytx["fwdtransforms"][1], "rb") as src, open(affine_path, "wb") as dst:
        dst.write(src.read())

    print(f" Saved registered JHU atlas for {subject_id}")

"""## Controls Histogram Calculation"""

import os
import numpy as np
import nibabel as nib

subjects_dir = "/content/drive/MyDrive/TejaswiAbburi_va797/Dataset/NIFD_complete_dataset/NIFD_Controls/NIFD_Controls_DTI_parameters"
atlas_dir    = "/content/drive/MyDrive/TejaswiAbburi_va797/Dataset/NIFD_complete_dataset/registered_JHU_labels"
output_file  = "/content/drive/MyDrive/TejaswiAbburi_va797/Dataset/NIFD_Histogram_Features/FA"

roi_labels = [5, 7, 8, 16, 18, 36, 37, 38, 39]

n_bins = 20
bin_edges = np.linspace(0, 1, n_bins + 1)

features_all = []
subject_ids = []

for subject_id in sorted(os.listdir(subjects_dir)):
    subject_path = os.path.join(subjects_dir, subject_id)
    if not os.path.isdir(subject_path):
        continue

    fa_file = None
    for f in os.listdir(subject_path):
        if f.startswith("tensor_fa") and f.endswith(".nii.gz"):
            fa_file = os.path.join(subject_path, f)
            break

    if fa_file is None:
        print(f"Skipping {subject_id} (FA not found)")
        continue

    atlas_file = os.path.join(atlas_dir, f"{subject_id}_JHU_labels.nii.gz")
    if not os.path.exists(atlas_file):
        print(f"Skipping {subject_id} (atlas not found)")
        continue

    fa_img  = nib.load(fa_file)
    fa_data = fa_img.get_fdata()

    atlas_img  = nib.load(atlas_file)
    atlas_data = atlas_img.get_fdata().astype(int)

    subj_features = []
    for roi in roi_labels:
        roi_mask = (atlas_data == roi)
        fa_vals  = fa_data[roi_mask]

        if fa_vals.size == 0:
            hist = np.zeros(n_bins)
        else:
            hist, _ = np.histogram(fa_vals, bins=bin_edges)
            hist = hist / fa_vals.size

        subj_features.extend(hist)

    features_all.append(subj_features)
    subject_ids.append(subject_id)

features_all = np.array(features_all)

np.save(output_file + ".npy", features_all)
np.save(output_file + "_subjects.npy", np.array(subject_ids))

print("Normalized FA histogram feature extraction done")
print("Feature matrix shape:", features_all.shape)
print("Subjects saved:", len(subject_ids))

"""## Patients Histogram Calculation"""

import os
import numpy as np
import nibabel as nib

subjects_dir = "/content/drive/MyDrive/TejaswiAbburi_va797/Dataset/NIFD_complete_dataset/NIFD_Patients/NIFD_Patients_DTI_parameters"
atlas_dir    = "/content/drive/MyDrive/TejaswiAbburi_va797/Dataset/NIFD_complete_dataset/registered_JHU_labels_Patients"
output_file  = "/content/drive/MyDrive/TejaswiAbburi_va797/Dataset/NIFD_Histogram_Features/FA"

roi_labels = [5, 7, 8, 16, 18, 36, 37, 38, 39]

n_bins = 20
bin_edges = np.linspace(0, 1, n_bins + 1)

features_all = []
subject_ids = []

for subject_id in sorted(os.listdir(subjects_dir)):
    subject_path = os.path.join(subjects_dir, subject_id)
    if not os.path.isdir(subject_path):
        continue

    fa_file = None
    for f in os.listdir(subject_path):
        if f.startswith("tensor_fa") and f.endswith(".nii.gz"):
            fa_file = os.path.join(subject_path, f)
            break

    if fa_file is None:
        print(f"Skipping {subject_id} (FA not found)")
        continue

    atlas_file = os.path.join(atlas_dir, f"{subject_id}_JHU_labels.nii.gz")
    if not os.path.exists(atlas_file):
        print(f"Skipping {subject_id} (atlas not found)")
        continue

    fa_img  = nib.load(fa_file)
    fa_data = fa_img.get_fdata()

    atlas_img  = nib.load(atlas_file)
    atlas_data = atlas_img.get_fdata().astype(int)

    subj_features = []
    print(f"\nSubject {subject_id} voxel counts per ROI:")
    for roi in roi_labels:
        roi_mask = (atlas_data == roi)
        fa_vals  = fa_data[roi_mask]

        voxel_count = fa_vals.size
        print(f"  ROI {roi}: {voxel_count} voxels")

        if voxel_count == 0:
            hist = np.zeros(n_bins)
        else:
            hist, _ = np.histogram(fa_vals, bins=bin_edges)
            hist = hist / voxel_count

        subj_features.extend(hist)

    features_all.append(subj_features)
    subject_ids.append(subject_id)

features_all = np.array(features_all)

np.save(output_file + ".npy", features_all)
np.save(output_file + "_subjects.npy", np.array(subject_ids))

print("\n Normalized FA histogram feature extraction done")
print("Feature matrix shape:", features_all.shape)
print("Subjects saved:", len(subject_ids))